[{"content":"","date":"22 January 2026","externalUrl":null,"permalink":"/","section":"/home/noe","summary":"","title":"/home/noe","type":"page"},{"content":"","date":"22 January 2026","externalUrl":null,"permalink":"/tags/agones/","section":"Tags","summary":"","title":"Agones","type":"tags"},{"content":"","date":"22 January 2026","externalUrl":null,"permalink":"/tags/go/","section":"Tags","summary":"","title":"Go","type":"tags"},{"content":"","date":"22 January 2026","externalUrl":null,"permalink":"/tags/kubernetes/","section":"Tags","summary":"","title":"Kubernetes","type":"tags"},{"content":"If you\u0026rsquo;re interested in Kubernetes like I am, you\u0026rsquo;ve probably found yourself exploring related projects on GitHub and you might have stumbled upon a repository called Agones. If you\u0026rsquo;ve never heard about it, Agones is a project created by Google to manage and deploy video game servers on Kubernetes.\nRecently, I dipped my toes in the water and tried it out. I had a lot of fun doing so and I want to share everything I learned. In this article, we will go over the following:\nThe creation of a basic game server in Go. Integrating it with Agones\u0026rsquo; SDK. Its deployment on Kubernetes with Agones. The making of a matchmaking service in Go. Setting up and benchmarking autoscaling for our infrastructure based on the matchmaking\u0026rsquo;s player queue. I\u0026rsquo;ll share a lot of relevant code snippets and diagrams, but if you want to get the full picture, you can find the source code and the Kubernetes manifests in this GitHub repository:\nnoetarbouriech/agones-rps-game A rock paper scissors game in Go deployed on K8s with Agones Go 0 0 Why Agones # Before going any further, we need to address a question regarding Agones: Why does it even exist? That was my first reaction upon discovering Agones because, in theory, anyone can just deploy their game server as a regular deployment on a cluster, right? Well, things are actually a bit more complicated than that.\nIf you look into the Agones documentation, you will find this section which basically answers the question. To put it simply, game server workloads are both stateful and stateless. An empty game server is stateless and can be safely deleted or moved, while a game server with players probably has in-memory state and must not leave the node.\nIn other words, Agones allows you to manage and scale game server workloads based not only on CPU, memory, or traffic but also on player activity. Thanks to that, you can update game servers without shutting down servers with active players, reuse a game server on which a game has ended or even set autoscaling based on the number of full game servers. And much more.\nDeveloping a game server in Go # Note If you don\u0026rsquo;t care about the dev part or if you already have a game server you want to deploy, you can skip to this part: ‚Üì Adding Agones to a game server\nTo start, we obviously need a game to work with. For this purpose, I will be making a quick and simple game of rock paper scissors in Go.\nSince this is just a simple demo, I won\u0026rsquo;t be trying to make something grandiose. It will just be a basic HTTP server with a WebSocket on which two players will connect to battle. For a real game, you would probably want to use UDP connections.\nBoth players will be connected to the WebSocket and will have to select their move. The connection stays open for both players until they both selected a move. Once both players chose their moves, the server sends the winner to them.\nTo do this, I used standard Go packages such as net/http and github.com/gorilla/websocket.\nmain.go 1package main 2 3//go:embed index.html 4var index embed.FS 5 6var game *Game 7 8func main() { 9\t// Inititalize the game 10\tgame = NewGame() 11 12\thttp.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { 13\thttp.FileServer(http.FS(index)).ServeHTTP(w, r) 14\t}) 15\thttp.HandleFunc(\u0026#34;/ws\u0026#34;, game.ws) 16\tlog.Println(\u0026#34;Starting HTTP server on port 3000\u0026#34;) 17\tlog.Fatal(http.ListenAndServe(\u0026#34;:3000\u0026#34;, nil)) 18} The root path (/) serves the index.html file (which is embedded in the binary) and the /ws path serves the WebSocket connection.\nWarning When making a game server, you should avoid using ports 8080, 9357 and 9358 in your container image as these will be used by the Agones sidecar container.\nThe index.html is just a very basic web page with buttons for each move (rock, paper, scissors). It uses JavaScript to send a message to the WebSocket when a button is clicked. Results are displayed in the result div.\nindex.html 1\u0026lt;div\u0026gt; 2 \u0026lt;h1\u0026gt;Rock Paper Scissors\u0026lt;/h1\u0026gt; 3 4 \u0026lt;button onclick=\u0026#34;send(\u0026#39;rock\u0026#39;)\u0026#34;\u0026gt;ü™®\u0026lt;/button\u0026gt; 5 \u0026lt;button onclick=\u0026#34;send(\u0026#39;paper\u0026#39;)\u0026#34;\u0026gt;üìÑ\u0026lt;/button\u0026gt; 6 \u0026lt;button onclick=\u0026#34;send(\u0026#39;scissors\u0026#39;)\u0026#34;\u0026gt;‚úÇÔ∏è\u0026lt;/button\u0026gt; 7 8 \u0026lt;div id=\u0026#34;result\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; 9\u0026lt;/div\u0026gt; 10 11\u0026lt;script\u0026gt; 12 const ws = new WebSocket(\u0026#34;ws://\u0026#34; + location.host + \u0026#34;/ws\u0026#34;); 13 14 ws.onmessage = (e) =\u0026gt; { 15 document.getElementById(\u0026#34;result\u0026#34;).innerHTML = e.data; 16 }; 17 18 function send(choice) { 19 ws.send(choice); 20 } 21 22 window.addEventListener(\u0026#34;beforeunload\u0026#34;, () =\u0026gt; { 23 ws.close(); 24 }); 25\u0026lt;/script\u0026gt; I won\u0026rsquo;t go too much into details about the game logic since, well, it\u0026rsquo;s just a simple game of rock paper scissors.\nThe game loop is fully coded in the WebSocket handler, and it uses methods from the game package located in ./internal/game. Here\u0026rsquo;s a basic overview of what this handler does:\nmain.go 1func (s *Server) ws(w http.ResponseWriter, r *http.Request) { 2\tconn, _ := upgrader.Upgrade(w, r, nil) 3\tdefer conn.Close() // Ensure connection is always closed when the handler exits. 4 5\t// Create a new player based on the connection 6\tplayer := game.NewPlayer(conn) 7\ts.game.AddPlayer(player) 8 9\t// Read the first message which should contain the player\u0026#39;s move 10\tmsgType, msg, err := conn.ReadMessage() 11\tif err != nil { 12\t// Client disconnected or error occurred 13\ts.game.RemovePlayer(player) 14\treturn 15\t} 16 17\t// Play the current player\u0026#39;s move 18\ts.game.PlayMove(player, string(msg)) 19 20\t// Check if the two players have played 21\tif s.game.Ended() { 22\ts.game.SendResults() 23\treturn 24\t} 25 26\t// First player gets into a loop waiting for the opponent\u0026#39;s move 27\tplayer.Send(\u0026#34;Waiting for opponent...\\n\u0026#34;) 28\tfor { 29\t_, _, err := conn.ReadMessage() 30\tif err != nil { 31\t// Client disconnected or error occurred 32\ts.game.RemovePlayer(player) 33\treturn 34\t} 35\t} 36} If you try to make something similar, keep in mind that you have to handle what happens when a player disconnects or leaves the game. In this case, I just made it so the player gets deleted from the game allowing them or someone else to rejoin. You may want to just end the game or kick everyone else if one of the players disappears.\nIn order to manage concurrency, I use a simple mutex to ensure that the player list and moves are not modified at the same time. Before every operation, I lock the mutex and unlock it after the operation is complete. For example:\ngame.go 1type Game struct { 2\tplayers []*Player 3\tmu sync.Mutex 4} 5 6... 7 8func (g *Game) AddPlayer(player *Player) { 9\tif len(g.players) \u0026gt;= 2 || player == nil { 10\treturn 11\t} 12 13\tg.mu.Lock() 14\tdefer g.mu.Unlock() 15\tg.players = append(g.players, player) 16\tlog.Printf(\u0026#34;Player %p added to game\u0026#34;, player) 17} Upon game end, the WebSocket connections are closed and the game server shuts down.\nThe end result looks like this:\nVery impressive, isn\u0026rsquo;t it? Jokes aside, this simple multiplayer game will be more than enough for us to get started with Agones.\nTip For this quick demo, I made a game server which is running only a single game instance to keep things simple. In our case, it would make more sense to have \u0026ldquo;rooms\u0026rdquo; and be able to host multiple game instances in a single container. You can find out more about this in High Density GameServers | Agones.\nAdding Agones to a game server # Now that we have a game server ready, we need to make some tweaks in order to deploy it with Agones. If you try to deploy it as of right now, it will just crash as Agones expects your container to send regular ping.\nTo explain briefly how things work in Agones, when deploying a game server, we use the well named GameServer resource. You can think of GameServers as the equivalent of Pods in the Agones world. They are what will be running your game server container.\nThe main difference with regular Pods is that GameServers run your image alongside an Agones SDK sidecar which is responsible for managing the lifecycle of the game server. This sidecar is responsible for ensuring that the game server is healthy and available for players. It communicates with the Kubernetes API to update the GameServer resource status.\n--- title: GameServer Architecture config: look: handDrawn --- graph TD KubeAPI[\"kube-apiserver\"] subgraph GameServer[\"GameServer\"] subgraph Pod[\"Pod\"] GameContainer[\"**Your Game Server** *Container*\"] AgonesSidecar[\"**agones-sdk** *Container*\"] GameContainer \u003c--\u003e|SDK gRPC| AgonesSidecar end end AgonesSidecar --\u003e|HTTP PATCH GameServer resource| KubeAPI The bare minimum to get your game server up and running with Agones is to implement a Health Check. To do this, we first need to import the Agones Game Server Client SDK. In my case, I will be importing the Go package but there are also SDKs for other languages such as Java or C++ and also for game engines such as Unity or Unreal Engine.\nEven if your language or game engine doesn\u0026rsquo;t have an SDK, you can still use Agones by making and deploying a sidecar container alongside your game server. This sidecar container would be responsible for communicating with Agones and you would just need to communicate with your game binary. Or else, you can just communicate directly with Agones using the gRPC API or the HTTP API which should be supported by most languages.\nOnce we have our SDK installed, we need to actually implement the health check. This is usually done by creating a loop that sends a ping to Agones every few seconds. Here\u0026rsquo;s how you can do it in Go:\nmain.go 1func main() { 2\t... 3\tgo HealthPing(sdk, ctx) 4} 5 6func HealthPing(sdk *sdk.SDK, ctx context.Context) { 7\ttick := time.Tick(2 * time.Second) 8\tfor { 9\terr := sdk.Health() 10\tif err != nil { 11\tlog.Fatalf(\u0026#34;Could not send health ping, %v\u0026#34;, err) 12\t} 13\tselect { 14\tcase \u0026lt;-ctx.Done(): 15\tlog.Print(\u0026#34;Stopped health pings\u0026#34;) 16\treturn 17\tcase \u0026lt;-tick: 18\t} 19\t} 20} Now, we can technically already deploy our game server on a Kubernetes cluster with Agones by creating a GameServer with our game container image. However, we are far from production-ready. We still need to at least implement the following Agones functions:\nReady() - To indicate that the game server is ready to accept connections from players. Shutdown() - To tell Agones to shut down the game server. Implementing the Ready() function is pretty straightforward. We just need to call it from the SDK when starting the game server:\nmain.go 1func main() { 2\t... 3\t// Mark server ready 4\tif err := sdk.Ready(); err != nil { 5\tlog.Fatalf(\u0026#34;Failed to mark Ready: %v\u0026#34;, err) 6\t} 7\t8\tgo HealthPing(sdk, ctx) 9\t10\tlog.Fatal(http.ListenAndServe(\u0026#34;:3000\u0026#34;, nil)) 11} Info In theory, you would want your Ready() call to be after your HTTP listener or whatever you\u0026rsquo;re using is fully up and running. In this case, it doesn\u0026rsquo;t really matter as http.ListenAndServe is pretty much instantaneous.\nTip If you\u0026rsquo;re used to building apps for Kubernetes, you might have thought about implementing a readiness and a liveness probes. However, here, we don\u0026rsquo;t need those because Agones will manage the game server lifecycle for us.\nFor the Shutdown() function, things are a bit more complicated. What we want to do is to implement a graceful shutdown process. Basically, it means that we need our server to handle signals like SIGTERM politely by waiting for everything to complete before shutting down. It is especially important in order to avoid loss of player data or of an unsaved game for instance.\nFortunately, this pattern is pretty easy to implement in Go. We will be using the context package to handle cancellation and timeouts coupled with the signal package to handle, as its name implies, signals.\nWe are first going to need to create a context that will be used all throughout our server. In order to have it be cancellable with Unix signals, we will be creating it using signal.NotifyContext from the os/signal package. We can then, at the end of our main() function, have all of our code for shutting down our server after \u0026lt;-ctx.Done().\nmain.go 1func main() { 2\t// Set up signal handling for graceful shutdown 3\tctx, cancel := signal.NotifyContext(context.Background(), syscall.SIGTERM, syscall.SIGINT) 4\tdefer cancel() 5 6\t... 7 8\t// Initialize HTTP server 9\thttpServer := s.newHTTPServer() 10\tgo func() { 11\tlog.Println(\u0026#34;Starting HTTP server on port 3000\u0026#34;) 12\tif err := httpServer.ListenAndServe(); err != nil \u0026amp;\u0026amp; err != http.ErrServerClosed { 13\tlog.Fatalf(\u0026#34;Failed to start HTTP server: %v\u0026#34;, err) 14\t} 15\t}() 16 17\t// Wait for shutdown signal 18\t\u0026lt;-ctx.Done() 19 20\t// Shutting down everything 21\tlog.Println(\u0026#34;Shutting down...\u0026#34;) 22\ts.sdk.Shutdown() 23\ts.game.Shutdown() 24\thttpServer.Shutdown(ctx) 25} Currently, we handle shutdown from signals correctly, but not necessarily gracefully. In general, when implementing this pattern, we want to ensure that all ongoing operations are completed before shutting down. In our case, this isn\u0026rsquo;t really important as the process of shutting down the client SDK and the HTTP server should be pretty straightforward.\nHowever, let\u0026rsquo;s say you\u0026rsquo;re making an actual game: you may want to save the result of your game to a database, for example. In Kubernetes, Pods getting deleted are first sent a SIGTERM, and have a grace period of 30 seconds. After that, Kubernetes sends a SIGKILL, which you want to avoid if possible. If for some reason the database you\u0026rsquo;re sending your data to is experiencing issues, you will want to rollback your transaction before being forcefully terminated.\nWe can achieve this by having a timeout, and to do that, we\u0026rsquo;re going to make, once again, a new context, but with context.WithTimeout() this time around. This way, we will be able to pass down the context with timeout to our different shutdown functions and ensure that our game server is properly shut down in a given amount of time.\nIn my case, I set it up with a timeout of 10 seconds. This is more than enough for the Agones client SDK and the HTTP server to shut down gracefully.\nmain.go 1func main() { 2\t... 3\t4\t// Wait for shutdown signal 5\t\u0026lt;-ctx.Done() 6 7\t// Create a context with a timeout for graceful shutdown 8\tshutdownCtx, cancel := context.WithTimeout(context.Background(), 10*time.Second) 9\tdefer cancel() 10 11\t// Shutting down everything 12\tlog.Println(\u0026#34;Shutting down...\u0026#34;) 13\ts.sdk.Shutdown() 14\ts.game.Shutdown() 15\thttpServer.Shutdown(shutdownCtx) 16} Tip What we just implemented is basically the 9th factor of the Twelve-Factor App methodology called \u0026ldquo;Disposability\u0026rdquo;. If you don\u0026rsquo;t know about this methodology, I highly recommend you to read it and implement it in your projects.\nWith all of this, we now have the lifecycle of our game server fully implemented and ready to be deployed alongside Agones\u0026rsquo; SDK sidecars in actual GameServer resources.\nDeploying a game server # Now that we have our game server ready, we can deploy it on a Kubernetes cluster. I\u0026rsquo;m using a basic kind cluster for this example, but you can use any Kubernetes cluster you want. The only important requirement is to install Agones on your cluster. To do so, you can simply use Helm chart like so:\nhelm repo add agones https://agones.dev/chart/stable helm repo update helm install my-release --namespace agones-system --create-namespace agones/agones We will be deploying our game server in the default namespace. If you want to deploy yours in a different one, you may need to change some values in your Helm deployment of Agones.\nOnce we have our cluster ready with Agones up and running, we can start by deploying our game server image in a simple GameServer resource:\ngameserver.yaml 1apiVersion: agones.dev/v1 2kind: GameServer 3metadata: 4 name: rps-game 5spec: 6 template: 7 ports: 8 - name: default 9 containerPort: 3000 10 protocol: TCP 11 spec: 12 containers: 13 - name: rps-game 14 image: ghcr.io/noetarbouriech/agones-rps-game/game You should then be able to see it by running kubectl get gameservers. You should see something like this:\nNAME STATE ADDRESS PORT NODE AGE rps-game Ready 192.168.97.2 7278 agones-cluster-control-plane 10s Notice how Agones picked a random port between 7000 and 8000 for the game server. This port is exposed on the host node\u0026rsquo;s network using the hostPort field of Pods. This means that you can access the game server directly from your host machine using the IP address and port number.\nYou can even check its events to see the different steps it went through:\nkubectl events --for=\u0026#39;GameServer/rps-game\u0026#39; Which should give you something like this:\nLAST SEEN TYPE REASON OBJECT MESSAGE 3m58s Normal Creating GameServer/rps-game Pod rps-game created 3m52s Normal Scheduled GameServer/rps-game Address and port populated 3m52s Normal RequestReady GameServer/rps-game SDK state change 3m52s Normal Ready GameServer/rps-game SDK.Ready() complete You should be able to access the game directly from your web browser by visiting http://ADDRESS:PORT.\nTip You can use the following to get the host IP and port:\nkubectl get gs -o jsonpath=\u0026#39;{.items[0].status.address}:{.items[0].status.ports[0].port}\u0026#39;Next, we can deploy the game server in a Fleet. If GameServers are the equivalent of Pods, you can think of Fleets as the equivalent of Deployments or StatefulSets. They allow us to have replicas of our GameServer and scale them up and down without killing active game servers. We can create one just like so:\nfleet.yaml 1apiVersion: agones.dev/v1 2kind: Fleet 3metadata: 4 name: rps-game 5spec: 6 replicas: 3 7 template: 8 spec: 9 ports: 10 - name: default 11 containerPort: 3000 12 protocol: TCP 13 template: 14 metadata: 15 labels: 16 app: rps-game 17 spec: 18 containers: 19 - name: rps-game 20 image: ghcr.io/noetarbouriech/agones-rps-game/game We can then check the GameServers it created:\nkubectl get gameservers NAME STATE ADDRESS PORT NODE AGE rps-game-4sxlg-bl6bh Ready 192.168.97.2 7447 agones-cluster-control-plane 4s rps-game-4sxlg-kfmbn Ready 192.168.97.2 7384 agones-cluster-control-plane 4s rps-game-4sxlg-kld5r Ready 192.168.97.2 7165 agones-cluster-control-plane 4s This fleet can easily be scaled up by running kubectl scale:\nkubectl scale fleet rps-game --replicas=5 But, right now, if you try to scale it down, it could kill active GameServers. What we want to do in order to avoid that is to use a GameServerAllocation. This type of resource allows us to set its state from Ready to Allocated, which will prevent Agones from deleting that GameServer. Let\u0026rsquo;s allocate a random GameServer from our fleet with kubectl:\nkubectl create -f - \u0026lt;\u0026lt;EOF apiVersion: allocation.agones.dev/v1 kind: GameServerAllocation spec: selectors: - matchLabels: agones.dev/fleet: rps-game EOF Now, let\u0026rsquo;s do something a bit extreme and scale the fleet down to 0 replicas:\nkubectl scale fleet rps-game --replicas=0 If you look at the list of GameServers, you\u0026rsquo;ll notice that the one we allocated is still there:\nNAME STATE ADDRESS PORT NODE AGE rps-game-4sxlg-bl6bh Allocated 192.168.97.2 7447 agones-cluster-control-plane 9m40s This is great, as we managed to scale down without stopping a GameServer that has been marked as being allocated for a game. If you go ahead and finish playing a game on this server, you\u0026rsquo;ll notice that the GameServer gets automatically deleted.\nOf course, in real life, you would probably use the Kubernetes API to allocate our GameServers instead of using kubectl. This way, we can automate the allocation process without manual intervention.\nTip You might also want to check out the Allocator Service as an alternative way to allocate GameServers from outside our Agones Kubernetes cluster.\nMaking a matchmaking service # So far, we managed to make a game server, hook it up to Agones and deploy it on a Kubernetes cluster. All of this is great but it\u0026rsquo;s nothing we couldn\u0026rsquo;t have achieved by simply using regular Kubernetes resources such as Deployments or StatefulSets. But now that we have everything set up, we can actually go a bit further and exploit Agones\u0026rsquo; features to have a matchmaking service which will scale our game servers automatically based on demand üöÄ.\nOr, at least, that\u0026rsquo;s what we\u0026rsquo;re going to do in the next part of this post. For now, we\u0026rsquo;ll focus on making a matchmaking service that will match 2 players together and will allocate a GameServer to them.\nIf you look online, you might find an open-source solution for matchmaking called Open Match. It has been made by Google, and it can work with Agones, which is great. However, as of writing this, there hasn\u0026rsquo;t been any update in over 2 years. A second version of Open Match called Open Match 2 seems to be planned but there are no releases yet and only a single person seems to be working on it.\nNote Just to be clear, I\u0026rsquo;m not saying you should avoid using Open Match, but given the current state of the project, and that it would be overkill for our needs, we\u0026rsquo;ll be making our own simple matchmaking service instead.\nHere\u0026rsquo;s what we\u0026rsquo;ll be working with:\n--- config: look: handDrawn --- sequenceDiagram participant Player as üë§ Player participant WebSocketServer as üåê HTTP Server participant Topic_matchmaking as üìá Topic: matchmaking participant Matcher as ‚öôÔ∏è Matcher participant Topic_match_results as üìá Topic: match_results_{playerID} participant KubernetesAPI as ‚ò∏Ô∏è Kubernetes API Player-\u003e\u003eWebSocketServer: Connect via WebSocket WebSocketServer-\u003e\u003eWebSocketServer: Generate playerID WebSocketServer-\u003e\u003eTopic_match_results: Subscribe WebSocketServer-\u003e\u003eTopic_matchmaking: Publish playerID Topic_matchmaking-\u003e\u003eMatcher: Deliver playerID alt No one waiting Matcher-\u003e\u003eMatcher: Store playerID as waiting Note right of Matcher: Wait for next player else Another player waiting Matcher-\u003e\u003eKubernetesAPI: Allocate GameServer KubernetesAPI--\u003e\u003eMatcher: GameServer address Matcher-\u003e\u003eTopic_match_results: Publish match for both players Topic_match_results-\u003e\u003eWebSocketServer: Deliver match result WebSocketServer-\u003e\u003ePlayer: Redirect to match-ip:port end For simplicity‚Äôs sake, I copied the base structure of the game server and reused it in the matchmaking service. This is why we are once again working with an HTTP server serving a WebSocket on /ws. This time, we redirect the player by opening the web page the matchmaking service will return.\nThe core component of this matchmaking system is the Pub/Sub queue. As you can see on the diagram, we are working with two topics:\nmatchmaking: Player requests for a match. match_results_{playerID}: Topics for the response to the player. The brain of the operation is named the Matcher, and is basically a process that will take a player from the queue and match them with another one. Once a match is made, it will reserve a GameServer by creating a GameServerAllocation through the Kubernetes API. It then sends them both the server address they need to join via the match results topic of both player.\nTo work with Pub/Sub in Go, we\u0026rsquo;ll be using a great library called Watermill, which will simplify the task a lot. What\u0026rsquo;s great about this library is that it works with a lot of different options, including Kafka, RabbitMQ or even PostgreSQL. To keep things simple, I chose to go with a simple Go Channel which you can also use as a Pub/Sub with Watermill.\nHere\u0026rsquo;s how the WebSocket handler initiates the matchmaking process and waits for a match result with Watermill:\nmain.go 1func (s *Server) ws(w http.ResponseWriter, r *http.Request) { 2\tconn, _ := upgrader.Upgrade(w, r, nil) 3\tdefer conn.Close() // Ensure connection is always closed when the handler exits. 4 5\tplayerID := rand.Text() // random player ID 6\tplayerResultTopic := fmt.Sprintf(\u0026#34;match_results_%s\u0026#34;, playerID) 7 8\t// Publish the matchmaking request 9\tmsg := message.NewMessage(watermill.NewUUID(), []byte(playerID)) 10\tif err := s.pub.Publish(\u0026#34;matchmaking\u0026#34;, msg); err != nil { 11\tlog.Printf(\u0026#34;Failed to publish matchmaking message: %v\u0026#34;, err) 12\treturn 13\t} 14 15\t// Subscribe to the player\u0026#39;s result topic 16\tmessages, err := s.sub.Subscribe(s.ctx, playerResultTopic) 17\tif err != nil { 18\tlog.Printf(\u0026#34;Failed to subscribe to player result topic: %v\u0026#34;, err) 19\treturn 20\t} 21 22\t// Wait for a match result 23\tselect { 24\tcase \u0026lt;-s.ctx.Done(): 25\treturn // Exit if the server is shutting down 26\tcase msg := \u0026lt;-messages: 27\tmatchResult := string(msg.Payload) 28\tlog.Printf(\u0026#34;Match found for player %s: %s\u0026#34;, playerID, matchResult) 29 30\t// Send the match result back to the WebSocket client 31\tif err := conn.WriteMessage(websocket.TextMessage, []byte(matchResult)); err != nil { 32\tlog.Printf(\u0026#34;Failed to send match result: %v\u0026#34;, err) 33\treturn 34\t} 35 36\t// Acknowledge the message and exit 37\tmsg.Ack() 38\treturn 39\t} 40} As you can see, it\u0026rsquo;s pretty straightforward with functions such as Subscribe() and Publish().\nThat\u0026rsquo;s basically it for the \u0026ldquo;frontend\u0026rdquo; part of the matchmaking service, but there\u0026rsquo;s a second part which is called the matcher. It runs as a goroutine but it could be run as a separate service if we were to use another Pub/Sub. It\u0026rsquo;s responsible for matching two players from the matchmaking queue.\nTo do that, I used a Router from Watermill, which gives a lot of features that are pretty nice to build event-driven systems. In our case, I\u0026rsquo;m just using it to add a handler for the matchmaking topic, which can be done just like this:\nrouter, _ := message.NewRouter(message.RouterConfig{}, logger) router.AddConsumerHandler( \u0026#34;matchmaking_handler\u0026#34;, // Name of the handler \u0026#34;matchmaking\u0026#34;, // Topic to subscribe to m.sub, // Subscriber m.matchmakingHandler, // Handler function, ) Handler functions in Watermill work like you would expect, by taking a message as input to process it.\nmatcher.go 1func (m *Matcher) matchmakingHandler(msg *message.Message) error { 2\t// Process the matchmaking message 3\tplayerID := string(msg.Payload) 4\tlog.Printf(\u0026#34;Processing player: %s\u0026#34;, playerID) 5 6\tm.mu.Lock() 7\tdefer m.mu.Unlock() 8 9\tif m.waiting == \u0026#34;\u0026#34; { 10\tm.waiting = Player(playerID) 11\treturn nil 12\t} 13 14\tvar matchResult string 15\tvar err error 16\tretryInterval := 5 * time.Second 17 18\tfor { 19\tmatchResult, err = AllocateGameServer() 20\tif err == nil { 21\tbreak 22\t} 23\tlog.Printf(\u0026#34;Failed to allocate game server: %v\u0026#34;, err) 24\ttime.Sleep(retryInterval) 25\t} 26 27\tresultMsg := message.NewMessage(watermill.NewUUID(), []byte(matchResult)) 28 29\t// Publish the match result to the player\u0026#39;s topic 30\tplayerResultTopic := fmt.Sprintf(\u0026#34;match_results_%s\u0026#34;, playerID) 31\tif err := m.pub.Publish(playerResultTopic, resultMsg); err != nil { 32\tlog.Printf(\u0026#34;Failed to publish match result: %v\u0026#34;, err) 33\treturn err 34\t} 35 36\t// Publish the match result to the waiting player\u0026#39;s topic 37\twaitingResultTopic := fmt.Sprintf(\u0026#34;match_results_%s\u0026#34;, m.waiting) 38\tif err := m.pub.Publish(waitingResultTopic, resultMsg); err != nil { 39\tlog.Printf(\u0026#34;Failed to publish match result: %v\u0026#34;, err) 40\treturn err 41\t} 42 43\t// remove waiting player 44\tm.waiting = \u0026#34;\u0026#34; 45 46\t// no error 47\treturn nil 48} What\u0026rsquo;s really important are the parts that are highlighted. You should be able to see the basic matchmaking logic which is to set a player as waiting if no other player is waiting. And when a second player joins, match them together and publish the result to both players.\nNote Notice also how this time I don\u0026rsquo;t use any msg.Ack(). It\u0026rsquo;s because the function is automatically called by Watermill if the handler doesn\u0026rsquo;t return an error.\nLast but not least, we have to take a look at the AllocateGameServer() function which allocates a random GameServer and returns its IP and port. To do that, I simply use the Kubernetes API to create a resource like we made earlier.\nallocation := \u0026amp;v1.GameServerAllocation{ ObjectMeta: metav1.ObjectMeta{ GenerateName: \u0026#34;game-alloc-\u0026#34;, Namespace: \u0026#34;default\u0026#34;, }, Spec: v1.GameServerAllocationSpec{ Selectors: []v1.GameServerSelector{{ LabelSelector: metav1.LabelSelector{ MatchLabels: map[string]string{ \u0026#34;agones.dev/fleet\u0026#34;: \u0026#34;rps-game\u0026#34;, }, }, }}, }, } However, if you try deploying the matchmaking service just like that with a Deployment, it will actually not do anything. This is because by default, we are using the default ServiceAccount to access the Kubernetes API from our Pod. To fix this, we just need to create a new ServiceAccount and a RoleBinding that grants the necessary permission to create GameServerAllocation resources.\nsa.yaml1apiVersion: v1 2kind: ServiceAccount 3metadata: 4 name: matchmaking-sa 5 namespace: default role.yaml1apiVersion: rbac.authorization.k8s.io/v1 2kind: Role 3metadata: 4 name: gameserverallocator 5 namespace: default 6rules: 7 - apiGroups: [\u0026#34;allocation.agones.dev\u0026#34;] 8 resources: [\u0026#34;gameserverallocations\u0026#34;] 9 verbs: [\u0026#34;create\u0026#34;] rolebinding.yaml 1apiVersion: rbac.authorization.k8s.io/v1 2kind: RoleBinding 3metadata: 4 name: gameserverallocator-binding 5 namespace: default 6subjects: 7 - kind: ServiceAccount 8 name: matchmaking-sa 9 namespace: default 10roleRef: 11 kind: Role 12 name: gameserverallocator 13 apiGroup: rbac.authorization.k8s.io And then, we can use this newly created ServiceAccount in our Deployment:\ndeployment.yaml 1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: matchmaking 5spec: 6 replicas: 1 7 selector: 8 matchLabels: 9 app: matchmaking 10 template: 11 metadata: 12 labels: 13 app: matchmaking 14 spec: 15 serviceAccountName: matchmaking-sa 16 containers: 17 - name: matchmaking 18 image: ghcr.io/noetarbouriech/agones-rps-game/matchmaking 19 ports: 20 - containerPort: 3000 Now, we can just create a Service for this Deployment and access it using port-forwarding like that:\nkubectl port-forward service/matchmaking 3000:80 If we access the matchmaking service at localhost:3000 and try to play a game, we get this:\nAs you can see from the screen briefly flashing to black, the matchmaking service indeed redirects to a game server once a match is found.\nSomething to keep in mind is that in its current state, the matchmaking is not scalable. You can\u0026rsquo;t really run multiple instances of the matchmaking as you could end up with players stuck in different matcher\u0026rsquo;s instances.\nHowever, it shouldn\u0026rsquo;t really matter as you can shard the matchmaking service by region (eu, us, etc.) or skill-level (Elo, rank). Then, you can have an instance of the matchmaking service for each shard. For example, you could have an instance running only on eu.elo100-200.matchmaking and one on us.elo100-200.matchmaking.\nAlso, I used a WebSocket again because I shamelessly copy-pasted the code from the game server as the base for the matchmaking service. However, you would be better off using an HTTP API where you issue a ticket and poll the match result. Or, maybe even SSE?\nSetting up autoscaling of game servers # Everything works pretty well so far, right? Well, there\u0026rsquo;s still a problem that remains to be solved. If you\u0026rsquo;ve followed along until now, so far we have a game running on Agones. There are multiple instances and a matchmaking service that routes each player to one of them. However, if we have 6 players all playing at the same time, we\u0026rsquo;ll end up with our 3 games instances being allocated, making it impossible for the matchmaking service to find a game for any new players.\nTo solve this issue, we have to set up autoscaling for our fleet of game servers. To do that, we need to create a FleetAutoscaler:\nfleetautoscaler.yaml 1apiVersion: \u0026#34;autoscaling.agones.dev/v1\u0026#34; 2kind: FleetAutoscaler 3metadata: 4 name: rps-game-autoscaler 5spec: 6 fleetName: rps-game 7 policy: 8 # type of the policy 9 type: Buffer 10 buffer: 11 # Size of a buffer of \u0026#34;ready\u0026#34; game server instances 12 bufferSize: 10 13 maxReplicas: 100 14 sync: 15 type: FixedInterval 16 fixedInterval: 17 # the time in seconds between each auto scaling 18 seconds: 5 I set it up with a buffer policy which ensures that there\u0026rsquo;s always a buffer of ready game servers available. In this case, I set it to 10 instances which are checked every 5 seconds.\nThere are other policies which are also interesting to look at such as:\nThe counter policy which scales based on a GameServer counter. It can be useful if you set up multiple rooms in a single game instance like I mentioned earlier. The webhook policy which allows us to scale based on a custom logic we can implement as a webhook handler. We can, for instance, scale it based on the number of players waiting in the matchmaking system. The WASM policy which as its name implies, allows us to scale based on a custom logic using WebAssembly modules. I have yet to find a use case for it, but it\u0026rsquo;s definitely interesting to explore. The Schedule policy which is pretty neat as it allows us to set a policy for a specific time period. It can be useful to scale up during an event or for the release of a game, for example. For simplicity‚Äôs sake, we\u0026rsquo;ll continue with the buffer policy as it works decently well if we set the sync interval to a low value.\nNow, for the fun part, let\u0026rsquo;s put this autoscaling to the test!\nThere\u0026rsquo;s a tool called k6 which is a load testing tool made by Grafana that can be used to simulate a large number of users connecting to our game server. We can use it to test our autoscaling policy and see how it performs under load. It simulates users with a custom script that can be written in JavaScript.\nHere\u0026rsquo;s the one I made for this project:\nscript.js 1import ws from \u0026#34;k6/ws\u0026#34;; 2import http from \u0026#34;k6/http\u0026#34;; 3import { check } from \u0026#34;k6\u0026#34;; 4 5export const options = { 6 vus: parseInt(__ENV.K6_VUS) || 100, 7 duration: __ENV.K6_DURATION || \u0026#34;20s\u0026#34;, 8}; 9 10export default function () { 11 const wsURL = \u0026#34;ws://localhost:3000/ws\u0026#34;; 12 13 const params = { tags: { test: \u0026#34;websocket-match\u0026#34; } }; 14 15 const res = ws.connect(wsURL, params, function (socket) { 16 socket.on(\u0026#34;open\u0026#34;, function open() { 17 console.log(\u0026#34;Connected to matchmaking\u0026#34;); 18 }); 19 20 socket.on(\u0026#34;message\u0026#34;, function message(data) { 21 const matchURL = data.toString().trim(); 22 console.log(`Received match URL: ${matchURL}`); 23 24 // Make HTTP GET request to the match URL 25 const httpRes = http.get(matchURL); 26 27 // Check if the HTTP request was successful 28 check(httpRes, { 29 \u0026#34;match URL status is 200\u0026#34;: (r) =\u0026gt; r.status === 200, 30 }); 31 32 console.log(`HTTP Response status: ${httpRes.status}`); 33 34 socket.close(); 35 }); 36 37 socket.on(\u0026#34;close\u0026#34;, function close() { 38 console.log(\u0026#34;WebSocket disconnected\u0026#34;); 39 }); 40 41 socket.on(\u0026#34;error\u0026#34;, function error(err) { 42 console.log(\u0026#34;WebSocket error:\u0026#34;, err); 43 }); 44 }); 45 46 // Check WebSocket connection status 47 check(res, { 48 \u0026#34;websocket status is 101\u0026#34;: (r) =\u0026gt; r \u0026amp;\u0026amp; r.status === 101, 49 }); 50} As you can see, this script that is definitely not AI-generated opens the WebSocket connection with the matchmaking service and just sends a GET request to the game server.\nWe\u0026rsquo;ll be running this script in k6 with 100 virtual users for a duration of 30 seconds.\nAnd here\u0026rsquo;s the result:\nk6 output logs ‚ñà TOTAL RESULTS checks_total.......: 220 4.398727/s checks_succeeded...: 100.00% 220 out of 220 checks_failed......: 0.00% 0 out of 220 ‚úì match URL status is 200 ‚úì websocket status is 101 HTTP http_req_duration..............: avg=1.44ms min=354.87¬µs med=1.31ms max=5.49ms p(90)=2.14ms p(95)=2.54ms { expected_response:true }...: avg=1.44ms min=354.87¬µs med=1.31ms max=5.49ms p(90)=2.14ms p(95)=2.54ms http_req_failed................: 0.00% 0 out of 110 http_reqs......................: 110 2.199363/s EXECUTION iteration_duration.............: avg=23.13s min=106.02ms med=24.19s max=46.16s p(90)=45.77s p(95)=46.14s iterations.....................: 110 2.199363/s vus............................: 40 min=40 max=100 vus_max........................: 100 min=100 max=100 NETWORK data_received..................: 170 kB 3.4 kB/s data_sent......................: 37 kB 739 B/s WEBSOCKET ws_connecting..................: avg=26.93ms min=3.49ms med=35.46ms max=44.52ms p(90)=41.99ms p(95)=42.34ms ws_msgs_received...............: 110 2.199363/s ws_session_duration............: avg=23.13s min=105.98ms med=24.19s max=46.16s p(90)=45.77s p(95)=46.14s ws_sessions....................: 150 2.999132/s running (50.0s), 000/100 VUs, 110 complete and 40 interrupted iterations default ‚úì [ 100% ] 100 VUs 20sAs you can see, the autoscaler has a hard time keeping up with the load. To avoid that, we can increase the buffer size and decrease the sync interval. Or even better, switch to the webhook policy and implement a webhook endpoint which exposes the number of players currently waiting for a game server allocation.\nTip The next step would be to improve the script to include actual game inputs with the game servers. With this, we could even imagine running a kind cluster with Agones and our game and k6 as part of CI tests.\nConclusion # This little experiment with Agones took longer than I first expected it to be, but I learned a lot and had quite some fun. Overall, I would say that Agones is very interesting in the way it transforms how we work with Kubernetes.\nI think making a game and a matchmaking system from scratch to work with Agones really helped me understand better how concepts would work together. I understood so much more about Agones doing it this way than I did at first when going through the documentation.\nStill, there are many things I haven\u0026rsquo;t tried, such as the other autoscaling policies, using counters and lists, or just working with an actual game server with real-time communication in UDP. There are also related projects such as Quilkin which is a UDP proxy that can be used to route traffic to game servers and seems to work well with Agones.\nI hope this article has been helpful for you and that you have learned something new about Agones and Kubernetes. I would appreciate any feedback you might have on this article. Thank you for reading!\n","date":"22 January 2026","externalUrl":null,"permalink":"/posts/making-and-scaling-a-game-server-in-k8s-using-agones/","section":"Posts","summary":"Learn with me how to create a game server in Go for Agones, deploying it on Kubernetes, designing an event-based matchmaking service also in Go, and setting up autoscaling for the whole thing.","title":"Making and Scaling a Game Server in Kubernetes using Agones","type":"posts"},{"content":"","date":"22 January 2026","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"22 January 2026","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"My first post on this blog. Nothing much to see here for now.\nThis blog is built using Hugo and hosted on GitHub Pages. I\u0026rsquo;m using the Blowfish theme.\n","date":"1 January 1970","externalUrl":null,"permalink":"/posts/hello-world/","section":"Posts","summary":"This is my first post on this website","title":"Hello World","type":"posts"},{"content":"Hello there \u0026#x1f44b;\nI‚Äôm No√© Tarbouriech, a French DevOps engineer, graduated from Polytech Montpellier. I previously worked at Numalis as a DevOps apprentice and at ESA as an intern.\nI\u0026rsquo;m passionate about topics such as Kubernetes (I\u0026rsquo;m a CKA), GitOps, Go, and cloud-native technologies in general. I enjoy learning new tools, experimenting with workflows, and this blog is where I share my experiences and lessons learned.\nIf you want to connect with me, you can find me on LinkedIn and GitHub.\nFeel free to reach out to me if you have any questions or just want to chat. I\u0026rsquo;m always happy to help and learn from others \u0026#x1f604;.\n","externalUrl":null,"permalink":"/about/","section":"/home/noe","summary":"","title":"About me","type":"page"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]